@InProceedings{10.1007/978-3-031-18910-4_15,
author="Hu, Yan
and Qiu, Zhongxi
and Zeng, Dan
and Jiang, Li
and Lin, Chen
and Liu, Jiang",
editor="Yu, Shiqi
and Zhang, Zhaoxiang
and Yuen, Pong C.
and Han, Junwei
and Tan, Tieniu
and Guo, Yike
and Lai, Jianhuang
and Zhang, Jianguo",
number=2,
title="SuperVessel: Segmenting High-Resolution Vessel from Low-Resolution Retinal Image",
booktitle="Pattern Recognition and Computer Vision",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="178--190",
abstract="Vascular segmentation extracts blood vessels from images and serves as the basis for diagnosing various diseases, like ophthalmic diseases. Ophthalmologists often require high-resolution segmentation results for analysis, which leads to super-computational load by most existing methods. If based on low-resolution input, they easily ignore tiny vessels or cause discontinuity of segmented vessels. To solve these problems, the paper proposes an algorithm named SuperVessel, which gives out high-resolution and accurate vessel segmentation using low-resolution images as input. We first take super-resolution as our auxiliary branch to provide potential high-resolution detail features, which can be deleted in the test phase. Secondly, we propose two modules to enhance the features of the interested segmentation region, including an upsampling with feature decomposition (UFD) module and a feature interaction module (FIM) with a constraining loss to focus on the interested features. Extensive experiments on three publicly available datasets demonstrate that our proposed SuperVessel can segment more tiny vessels with higher segmentation accuracy IoU over 6{\%}, compared with other state-of-the-art algorithms. Besides, the stability of SuperVessel is also stronger than other algorithms. The code will be released at https://github.com/Qsingle/Megvision.",
isbn="978-3-031-18910-4"
}
@INPROCEEDINGS{9995545,
  author={Zhang, Jiayi and Chen, Xiaoshan and Qiu, Zhongxi and Yang, Mingming and Hu, Yan and Liu, Jiang},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Hard Exudate Segmentation Supplemented by Super-Resolution with Multi-scale Attention Fusion Module}, 
  year={2022},
  volume={},
  number=3,
  pages={1375-1380},
  doi={10.1109/BIBM55620.2022.9995545}}

@INPROCEEDINGS{9629891,
  author={Wang, Yiming and Qiu, Zhongxi and Hu, Yan and Chen, Hao and Ye, Fangfu and Liu, Jiang},
  booktitle={2021 43rd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={Surgical instrument segmentation based on multi-scale and multi-level feature network}, 
  year={2021},
  volume={},
  number=4,
  pages={2672-2675},
  doi={10.1109/EMBC46164.2021.9629891}}
  
@InProceedings{10.1007/978-3-031-16525-2_12,
author="Li, Haojin
and Li, Heng
and Qiu, Zhongxi
and Hu, Yan
and Liu, Jiang",
editor="Antony, Bhavna
and Fu, Huazhu
and Lee, Cecilia S.
and MacGillivray, Tom
and Xu, Yanwu
and Zheng, Yalin",
title="Domain Adaptive Retinal Vessel Segmentation Guided by High-frequency Component",
booktitle="Ophthalmic Medical Image Analysis",
year="2022",
publisher="Springer International Publishing",
address="Cham",
number=5,
pages="115--124",
abstract="The morphological structure of retinal fundus blood vessels is of great significance for medical diagnosis, thus the automatic retinal vessel segmentation algorithm has become one of the research hotspots in the field of medical image processing. However, there are still several unsolved difficulties in this task: the existed methods are too sensitive to the low-frequency noise in the fundus images, and there are few annotated data sets available, and meanwhile, the retinal images of different datasets vary greatly. To solve the above problems, we propose a domain adaptive vessel segmentation algorithm with multiple image entrances called MIUnet, which is robust to the etiological noises and domain shift between diverse datasets. We apply Fourier domain adaptation and the high-frequency component filtering modules to transform the raw images into two styles, and simultaneously reduce the discrepancy between the source domain and target domain retinal images. After that, images produced by the two modules are fed into a multi-input deep segmentation model, and the full utilization of features from different modalities is ensured by the deep supervision mechanism. Experiments prove that, compared with other segmentation methods, the MIUnet has better performances in cross-domain experiments, where the IoU reaches 63{\%} when trained on ARIA dataset and tested on the DRIVE dataset and 53{\%} in the opposite direction.",
isbn="978-3-031-16525-2"
}
