@article{QIU2022105628,
title = {FGAM: A pluggable light-weight attention module for medical image segmentation},
journal = {Computers in Biology and Medicine},
volume = {146},
pages = {105628},
year = {2022},
issn = {0010-4825},
number = 1,
doi = {https://doi.org/10.1016/j.compbiomed.2022.105628},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522004206},
author = {Zhongxi Qiu and Yan Hu and Jiayi Zhang and Xiaoshan Chen and Jiang Liu},
keywords = {Medical image segmentation, Attention mechanism, Encoder-decoder network},
abstract = {Medical image segmentation is fundamental for computer-aided diagnosis or surgery. Various attention modules are proposed to improve segmentation results, which exist some limitations for medical image segmentation, such as large computations, weak framework applicability, etc. To solve the problems, we propose a new attention module named FGAM, short for Feature Guided Attention Module, which is a simple but pluggable and effective module for medical image segmentation. The FGAM tries to dig out the feature representation ability in the encoder and decoder features. Specifically, the decoder shallow layer always contains abundant information, which is taken as a queryable feature dictionary in the FGAM. The module contains a parameter-free activator and can be deleted after various encoder-decoder networksâ€™ training. The efficacy of the FGAM is proved on various encoder-decoder models based on five datasets, including four publicly available datasets and one in-house dataset.}
}